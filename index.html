<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    
    <title>Evolving minds for fun and profit</title>
    
    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/extra.css">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/beige.css">
    
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/monokai.css">
    
    <!-- Printing and PDF exports -->
    <script>
     var link = document.createElement( 'link' );
     link.rel = 'stylesheet';
     link.type = 'text/css';
     link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
     document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <div class='footer'><a rel="license"
		 href="http://creativecommons.org/licenses/by-sa/4.0/"><img
		alt="Licencia de Creative Commons" style="border-width:0"
src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"
/></a><br />This work is under a <a rel="license"
				    href="http://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA
	  4.0 license</a>.</div>

        
	<section data-background='https://live.staticflickr.com/65535/49578882327_68a8036da7_o_d.jpg'>
	  <h1>Evolving minds for fun and profit</h1>
          <h2>Evolutionary computation for machine learning</h2>
          <aside class='notes'>This is the abstract I sent:
            "The current hype cycle AI is has taken away from the collective mind the use of other techniques that help find the best intelligence for a particular problem, or help evolve solutions to machine learning or any kind of problems. In this talk we will talk about the current state of evolutionary techniques for machine learning, from the low-level implementation tricks to make them run efficiently in current computing systems, to how this can be put to use evolving the 'brains" of game players, gaming backstories or racing cars"</aside>
        </section>

	<section data-background='https://live.staticflickr.com/65535/49578847727_957005c8e2_3k_d.jpg'>
	  <h1><code>@jjmerelo</code> | <code>JJ@GitHub</code></h1>
	  <h2 class='fragment'>Amateur cook, coder, wordsmith</h2>
	  <h2 class='fragment'>Professional professor @ UGR </h2>
	</section>




	<section data-background='img/tesis.png'>
	</section>

	<section data-background='https://live.staticflickr.com/65535/47645151581_ad2fbf8426_k_d.jpg'><h1>-20 AD</h1>
	  <h2 class='fragment'><strong>A</strong>nno <strong>D</strong>eep Learning</h2>
	  <aside class='notes'>So people could create complex classifiers and regression functions way before deep learning... Hum... So let's get back to basics</aside>
	</section>
		
        <section data-background='https://live.staticflickr.com/65535/47998722251_b0219b3b19_k_d.jpg'>
	    <h1>What is artificial intelligence?</h1>

	    <aside class='notes'>In those days, there were talks about
	    symbolic and subsymbolic artificial intelligence, as well
	    as different "paths": artificial life and bioinspiration,
	    fuzzy logic and, of course, neural networks. Nowadays all
	    statistical methods whose final objective is related to
	    human senses or capabilities or natural processes are
	    called artificial intelligence. But nowadays, things seem
	    to have converged.</aside>
	  </section>

	  <section data-background='https://live.staticflickr.com/2143/1576388303_3b60d5c088_o_d.jpg'>
	    <h1>Fast tensor arithmetic</h1>
	    <h2 class='fragment'>Done fast</h2>
	    <aside class='notes'>Multiply-accumulate arrays, or vectors. That's basically it. That is what TensorFlow does, and is the basis of most neural network algorithms. It's floating point arithmetic, but you can also use limited precision if you want.
	    </aside>
	  </section>

	  <section data-background='https://live.staticflickr.com/65535/49579044712_632a9a8480_o_d.jpg'>><h1>What's the path to artificial (general) intelligence?</h1>
	  </section>
	  
        <section
        data-background='https://live.staticflickr.com/16/22336624_ccf940d11a_o_d.jpg'>
          <h1>Intelligence, evolved</h1>
          <aside class='notes'>Bioinspiration is a strong force in
        modern heuristics applied to engineering. Looking at nature to find out how to solve
        problems. Yet it's not prevailing in artificial intelligence:
        concepts like learning or training are more important in that
        sense than evolving. Yet it's possible to find ways to evolve
        stuff that are simply better, more intelligent, than those
            based on simple solutions.</aside>
        </section>

        <section>
          <img src='img/trends.png' alt='Google trends'>
   <aside class='notes'>While interest in deep reinforcement learning
            is rising and it remains stable for deep learning,
     neuroevolution interest is close to 0. And that is bad, because...</aside>
        

        </section>

        <section data-background='https://live.staticflickr.com/3170/2767925997_f17cdfdc4f_o_d.jpg'>
          <h1>Evolution is search</h1>
          <aside class='notes'>And the search space is guided and
          defined by yourself. You don't need to constrain yourself to
            a pre-established set of solutions. But... </aside>
        </section>

        <section data-background='https://live.staticflickr.com/8379/8619547463_95682e9eaf_3k_d.jpg'>
          <h1>Learning is adaptation</h1>
          <aside class='notes'>This is still a head, no matter
            what. It can be used for heady things.</aside>
        </section>

        <section
        data-background='https://live.staticflickr.com/1874/29431130077_bf54df50d3_o_d.jpg'>
          <h1>If you do hillclimbing</h1>
        </section>

        <section data-background='https://live.staticflickr.com/4755/28208869389_b397bef760_o_d.jpg'>
          <h2>...You will find the nearest summit</h2>
          <h1>You need to find <em>the highest</em> one</h1>
        </section>

        <!-- Evolutionary algorithms -->
        <section>
	  <section><h1>EAs are optimization methods</h1>
	    <h2 class='fragment'>Optimize this</h2>
	    <pre class='fragment'><code>sub road-royale ( @χ ) {
    @χ.rotor(4).map( {so @_.all + so @_.none}).sum;
}
	    </code></pre>
	    <aside class='notes'>It can optimize (or search if it can be formulated in terms of distances) any function. This function is often used because it's simple but it's also got some "neutral" changes: it increases fitness only when several things changes at the same time. Also includes junctions, and cool stuff.</aside>
	  </section>
	  
          <section>
	    <h2>Evolutionary algorithms evolve <strong>encoded</strong> solutions in populations</h2>
	    <pre><code>    my @population = ( Bool.pick() xx $length ) xx $population-size;
            </code></pre>

<aside class='notes'>Chromosomes are simply lists of random Bools, or bits. Other data structures are possible, but this works well for demos and many benchmark functions.</aside>
          </section>

          <section><h2>... through <strong>evaluation</strong>...</h2>
  <pre><code>my $evaluated = @population.unique.map( { @$_ => road-royale( @$_ ) } ).Mix;</code></pre>
<aside class='notes'>Mixes are immutable, so we're good here, but we need them to be unique or it will add the weights. Here's an interesting thing that I haven't seen in any other language; I'm using elements and its "weight" as score. This is going to be useful later on. Also, I'm using a cache so that I don't evaluate twice the same thing. It's not important at the beginning, but by the end of the simulation lots of values are going to be the same.</aside>

          </section>

          <section>
  <h2>... to <strong>select</strong> the best</h2>
<pre><code>          my @reproductive-pool = $evaluated.roll( $population-size );</code></pre>
<aside class='notes'>Since it's a Mix, just a roll takes care of
  selecting with a probability thats related to fitness</aside>
          </section>

          <section><h1>... and interchange bits ... </h1>
<pre><code>    my @pairs = @x Z @y;
    my $xover1point = @x.keys.pick;
    my $xover2point = ($xover1point^..@x.elems).pick;
    my @crossed =  gather for @pairs.kv -> $index, @value {
        take ( ($xover1point <= $index <= $xover2point) ?? @value.reverse !!
            @value );
    }
    return ([Z] @crossed).Slip;</code></pre>

					  <pre class='fragment'><code>@population.append:
  @reproductive-pool.pick( $population-size / 5 ).rotor(2)
    .map( { xover( @$_[0], @$_[1] ) } );</code></pre>
					  <aside class='notes'>These are selected randomly from all members in
  the population. Since the list is already randomized, we can just pick them by pairs. Also, 1/5 of the population is doing this. There's something called the rule of fifths, which I'm not going to bore you with, but it means that what we're doing is just right.</aside></section>

          <section><h1>... which mutate ...</h1>
<pre><code>sub mutate ( @x is copy ) {
    @x[ (^@x.elems).pick ] ?^= True;
    @x;
}</code></pre>

<pre class='fragment'><code>@population.append:
    @reproductive-pool.pick( $population-size*3/5).map( {mutate(@$_)} );
</code></pre>
    <aside class='notes'>It's a single bitflip of an element randomly
  chosen, which uses xor so that we don't need to store the mutation point in a variable. We again use map to process the population, functional style.</aside>
          </section>

          <section><h1>Repeat until solution is <strong>found</strong></h1>
  <pre><code>my $best-so-far = $evaluated.values.max;
@best = $evaluated.grep( *.value == $best-so-far );
if any( $evaluated.values ) == $length/4 {
    last;
}  </code></pre>  <aside class='notes'>We use junctions, so that we don't really have to sort the population. We also filter the best to add it to the next generation. Or until you get tired, whatever happens
    first.</aside>
          </section>

          <section><h1>We ♥ just the way you are</h1>
  <pre><code>@population.append: @reproductive-pool.pick( $population-size / 5 );</code></pre>
  <aside class='notes'>This is just random, so it might include or not the best.</aside>
          </section>
        </section>


	<!-- Doing neuroevolution -->

	<section>
	  <section data-background='https://live.staticflickr.com/1607/25039905211_fb9ec4e0c1_3k_d.jpg'>
            <h1>Let's evolve brains</h1>

            <aside class='notes'>This is a wonderful piece of street
              art by El niño de las pinturas. You should not miss
              it.</aside>

          </section>

	  <section><h1>Neural nets as data structures</h1>
	    <aside class='notes'>It's essential to know really what we are going to evolve, and it's not trivial to do that.</aside>
	  </section>

	  <section><h1>Weights?</h1>
	    <h2 class='fragment'>Or <strong>initial</strong> weights</h2>
	  </section>

	  <section><h1>Structure?</h1>
	    <h2 class='fragment'>Or blueprint to generate structure?</h2>
	  </section>

	  <section data-background='img/lvq-representation.png'>
	    <aside class='notes'>I used direct representation of initial weights, and direct representation of structure.</aside>
	  </section>

	  <section><h1>Be NEAT</h1>
            <h2>Neuroevolution of augmenting topoloties, Stanley et
            al.</h2>
            <img src='img/NEAT.png' alt='NEAT representation'>
            <aside class='notes'>There's much more to that. Image
            taken from: Kenneth O. Stanley & Risto Miikkulainen
            (2002). "Evolving Neural Networks Through Augmenting
            Topologies" (PDF). Evolutionary Computation. 10 (2):
            99–127. CiteSeerX
            10.1.1.638.3910. doi:10.1162/106365602320169811. PMID
              12180173.; that paper also presented NEAT. This is also
            an example of indirect representation</aside>
          </section>

          <section data-background='https://live.staticflickr.com/4892/31692076817_4d7830c1af_k_d.jpg'>
            <h1>Mutation: change/add/eliminate neurons</h1></section>

          <section>
            <h1>Crossover: interchange bunches of neurons</h1>
            <aside class='notes'>With the possible problem of
              conflicting representations, which is not such a big
            deal anyway.
            </aside>
          </section>

	</section> <!-- end neuroevolution -->

        <section>
          <section data-background='https://live.staticflickr.com/1250/1255183899_4430b60210_o_d.jpg'>
            <h1>How good is a neural net?</h1>
          </section>
          
          <section><h1>Cross-validation</h1>
            <h2 class='fragment'>We are evaluating
            <em>structures</em></h2>
          </section>

          <section data-background='https://live.staticflickr.com/4483/37308845940_d8b42eed44_k_d.jpg'>
            <h1>This is noisy</h1>
            <aside class='notes'>Every evaluation is going to return a
              different value</aside>
          </section>

          <section data-background='img/noisy-fitness.png'>
            <h3 class='fragment'>Merelo, Juan J., et al. "There is
            noisy lunch: A study of noise in evolutionary optimization
            problems." 2015 7th International Joint Conference on
            Computational Intelligence (IJCCI). Vol. 1. IEEE,
            2015.</h3>
            <aside class='notes'>There are several ways to deal with
            this. Point is, you can't simply evaluate once, results
              are not going to be crisp.</aside>
          </section>

        </section>

        <section>
          <section data-background='https://live.staticflickr.com/1890/42505283260_654c55a3a3_k_d.jpg'>
            <h1>Evolution bites back: Lamarckian evolution</h1>
            <h2 class='fragment'>Hillclimbing redux</h2>
          </section>

          <section>
            <h1>Baldwin effect: learning by being born</h1>

            <aside class='notes'>Learned behaviors eventually get
          coded in initial weights, or even structural constants, so
          that you need to learn less and less after being born. This
          was demonstrated visibly by the Spanish naturalist Rodríguez
          de la Fuente, who showed that a Spanish vulture, the
          alimoche, was able of using stones to break eggs withoug
              having seen it even a single time.</aside>
          </section>
        </section>

        <section> <!-- applications -->
          <section><h1>Time series forecasting... using the
          browser</h1>

            <aside class='notes'>This is a paper from 2017, Rivas,
        V. M., et al. "Time series forecasting using evolutionary
        neural nets implemented in a volunteer computing system."
        Intelligent Systems in Accounting, Finance and Management
        24.2-3 (2017): 87-95., but more recently we have implemented
              also this using Go and WebAssembler</aside>
              </section>


              <section data-background='https://live.staticflickr.com/1853/29292555287_b8b6d8533d_k_d.jpg'>
                <h1>Traffic prediction</h1>
                <aside class='notes'>It's in Spanish, but... Rivas, V. M., et al. "Predicción de tráfico mediante co-evolución de Redes Neuronales de Funciones de Base Radial y selección de variables de entrada." Ix Congreso Espanol De Metaheurısticas, Algoritmos Evolutivos Y Bioinspirados (MAEB 2013). Vol. 1. 2013.</aside>
              </section>

              <section><h1>Robot evolution</h1>
                <h2>Work by Eiben et al. in VU-Amsterdam</h2>
                <img
                src='https://www.frontiersin.org/files/Articles/126753/frobt-02-00004-HTML/image_m/frobt-02-00004-g001.jpg'
                alt='From the Frontiers article'>
                <aside class='notes'>In this case, fitness is
                implicit: if it survives, it's good enough. It's
                  evolution of robot shapes as well as their neural
                part. Open access article here: https://www.frontiersin.org/articles/10.3389/frobt.2015.00004/full</aside>
              </section>
        </section><!-- end applications -->


        <section><!-- Hands on -->
          <section>
            <h1>NEAT-Python + PyTorch NEAT</h1>
            <aside class='notes'>There's a whole freaking book about this...</aside>
          </section>
          
          <section><h1>Simply Keras/Tensorflow + DEAP</h1>
          </section>
        </section>

        <section>
          <h2>Let Nature be your guide</h2>
          <h1 class='fragment'>Neuroevolution FTW</h1>

          <aside class='notes'>Neuroevolution is able to find more
        compact, faster, more accurate classifiers or regression
            neural nets. Use them at ease.</aside>
        </section>

	<section data-background='https://live.staticflickr.com/65535/49578332203_9c9ba4c930_k_d.jpg'>
	  <h1>Questions?</h1></section>
      </div>
    </div>

    <script src="js/reveal.js"></script>
    
    <script>
     // More info about config & dependencies:
     // - https://github.com/hakimel/reveal.js#configuration
     // - https://github.com/hakimel/reveal.js#dependencies
     Reveal.initialize({
       hash: true,
       history: true,
       width: '99%',
       dependencies: [
	 { src: 'plugin/highlight/highlight.js' },
	 { src: 'plugin/notes/notes.js', async: true }
       ]
     });
    </script>
  </body>
</html>
